#!/usr/bin/env python3
"""
è§†é¢‘å¤„ç†APIæ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿåœ¨ä¸åŒè´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import requests
import time
import json
import sys
import argparse
import threading
import statistics
from typing import Dict, Any, List, Tuple
from datetime import datetime
import concurrent.futures

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self, api_base_url: str = "http://localhost:7878"):
        self.api_base_url = api_base_url
        self.session = requests.Session()
        self.session.timeout = 30
        
        # æµ‹è¯•ç”¨è§†é¢‘URL
        self.test_videos = [
            "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
            "https://www.youtube.com/watch?v=9bZkp7q19f0",
            "https://www.youtube.com/watch?v=jNQXAC9IVRw",
        ]
        
        self.results = {
            'response_times': [],
            'throughput_tests': [],
            'concurrent_tests': [],
            'resource_usage': []
        }
    
    def check_api_availability(self) -> bool:
        """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨"""
        try:
            response = self.session.get(f"{self.api_base_url}/health")
            return response.status_code == 200
        except:
            return False
    
    def measure_response_time(self, endpoint: str, method: str = 'GET', data: dict = None, iterations: int = 10) -> Dict[str, Any]:
        """æµ‹é‡APIç«¯ç‚¹å“åº”æ—¶é—´"""
        print(f"â±ï¸ æµ‹é‡ {endpoint} å“åº”æ—¶é—´ ({iterations}æ¬¡)...")
        
        response_times = []
        
        for i in range(iterations):
            start_time = time.time()
            
            try:
                if method.upper() == 'GET':
                    response = self.session.get(f"{self.api_base_url}{endpoint}")
                else:
                    response = self.session.post(f"{self.api_base_url}{endpoint}", json=data)
                
                end_time = time.time()
                response_time = end_time - start_time
                
                if response.status_code in [200, 503]:  # 503è¡¨ç¤ºèµ„æºé™åˆ¶ï¼Œä¹Ÿæ˜¯æ­£å¸¸å“åº”
                    response_times.append(response_time)
                
            except Exception as e:
                print(f"   âš ï¸ ç¬¬{i+1}æ¬¡è¯·æ±‚å¤±è´¥: {str(e)}")
            
            time.sleep(0.1)  # çŸ­æš‚é—´éš”
        
        if response_times:
            avg_time = statistics.mean(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            median_time = statistics.median(response_times)
            
            result = {
                'endpoint': endpoint,
                'method': method,
                'iterations': len(response_times),
                'avg_response_time': avg_time,
                'min_response_time': min_time,
                'max_response_time': max_time,
                'median_response_time': median_time,
                'success_rate': len(response_times) / iterations
            }
            
            print(f"   ğŸ“Š å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
            print(f"   ğŸ“Š æœ€å°/æœ€å¤§: {min_time:.3f}s / {max_time:.3f}s")
            print(f"   ğŸ“Š æˆåŠŸç‡: {result['success_rate']:.2%}")
            
            self.results['response_times'].append(result)
            return result
        else:
            print("   âŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥")
            return None
    
    def test_concurrent_requests(self, endpoint: str, method: str, data: dict, concurrent_users: int, duration: int) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        print(f"ğŸ”„ æµ‹è¯•å¹¶å‘è¯·æ±‚: {concurrent_users}ç”¨æˆ·, {duration}ç§’")
        
        results = []
        start_time = time.time()
        
        def worker():
            """å·¥ä½œçº¿ç¨‹"""
            session = requests.Session()
            session.timeout = 10
            
            while time.time() - start_time < duration:
                request_start = time.time()
                
                try:
                    if method.upper() == 'GET':
                        response = session.get(f"{self.api_base_url}{endpoint}")
                    else:
                        response = session.post(f"{self.api_base_url}{endpoint}", json=data)
                    
                    request_end = time.time()
                    
                    results.append({
                        'timestamp': request_start,
                        'response_time': request_end - request_start,
                        'status_code': response.status_code,
                        'success': response.status_code in [200, 503]
                    })
                    
                except Exception as e:
                    results.append({
                        'timestamp': request_start,
                        'response_time': 0,
                        'status_code': 0,
                        'success': False,
                        'error': str(e)
                    })
                
                time.sleep(0.1)  # çŸ­æš‚é—´éš”
        
        # å¯åŠ¨å¹¶å‘å·¥ä½œçº¿ç¨‹
        threads = []
        for _ in range(concurrent_users):
            thread = threading.Thread(target=worker)
            thread.start()
            threads.append(thread)
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # åˆ†æç»“æœ
        total_requests = len(results)
        successful_requests = len([r for r in results if r['success']])
        failed_requests = total_requests - successful_requests
        
        if successful_requests > 0:
            successful_results = [r for r in results if r['success']]
            avg_response_time = statistics.mean([r['response_time'] for r in successful_results])
            throughput = successful_requests / duration
        else:
            avg_response_time = 0
            throughput = 0
        
        result = {
            'endpoint': endpoint,
            'concurrent_users': concurrent_users,
            'duration': duration,
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'failed_requests': failed_requests,
            'success_rate': successful_requests / total_requests if total_requests > 0 else 0,
            'avg_response_time': avg_response_time,
            'throughput': throughput
        }
        
        print(f"   ğŸ“Š æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"   ğŸ“Š æˆåŠŸè¯·æ±‚: {successful_requests}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {result['success_rate']:.2%}")
        print(f"   ğŸ“Š å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        print(f"   ğŸ“Š ååé‡: {throughput:.2f} è¯·æ±‚/ç§’")
        
        self.results['concurrent_tests'].append(result)
        return result
    
    def monitor_resource_usage(self, duration: int) -> Dict[str, Any]:
        """ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ"""
        print(f"ğŸ’» ç›‘æ§èµ„æºä½¿ç”¨ ({duration}ç§’)...")
        
        resource_data = []
        start_time = time.time()
        
        while time.time() - start_time < duration:
            try:
                response = self.session.get(f"{self.api_base_url}/system/resources")
                
                if response.status_code == 200:
                    data = response.json()
                    resource_data.append({
                        'timestamp': time.time(),
                        'cpu_percent': data.get('cpu_percent', 0),
                        'memory_percent': data.get('memory_percent', 0),
                        'disk_percent': data.get('disk_percent', 0),
                        'active_tasks': data.get('active_tasks', 0),
                        'can_accept_tasks': data.get('can_accept_tasks', True)
                    })
                
            except Exception as e:
                print(f"   âš ï¸ èµ„æºç›‘æ§å¤±è´¥: {str(e)}")
            
            time.sleep(2)  # æ¯2ç§’é‡‡æ ·ä¸€æ¬¡
        
        if resource_data:
            cpu_values = [r['cpu_percent'] for r in resource_data]
            memory_values = [r['memory_percent'] for r in resource_data]
            disk_values = [r['disk_percent'] for r in resource_data]
            task_values = [r['active_tasks'] for r in resource_data]
            
            result = {
                'duration': duration,
                'samples': len(resource_data),
                'cpu_stats': {
                    'avg': statistics.mean(cpu_values),
                    'min': min(cpu_values),
                    'max': max(cpu_values),
                    'median': statistics.median(cpu_values)
                },
                'memory_stats': {
                    'avg': statistics.mean(memory_values),
                    'min': min(memory_values),
                    'max': max(memory_values),
                    'median': statistics.median(memory_values)
                },
                'disk_stats': {
                    'avg': statistics.mean(disk_values),
                    'min': min(disk_values),
                    'max': max(disk_values),
                    'median': statistics.median(disk_values)
                },
                'task_stats': {
                    'avg': statistics.mean(task_values),
                    'min': min(task_values),
                    'max': max(task_values),
                    'median': statistics.median(task_values)
                }
            }
            
            print(f"   ğŸ“Š CPUä½¿ç”¨ç‡: å¹³å‡{result['cpu_stats']['avg']:.1f}%, æœ€å¤§{result['cpu_stats']['max']:.1f}%")
            print(f"   ğŸ“Š å†…å­˜ä½¿ç”¨ç‡: å¹³å‡{result['memory_stats']['avg']:.1f}%, æœ€å¤§{result['memory_stats']['max']:.1f}%")
            print(f"   ğŸ“Š æ´»è·ƒä»»åŠ¡æ•°: å¹³å‡{result['task_stats']['avg']:.1f}, æœ€å¤§{result['task_stats']['max']}")
            
            self.results['resource_usage'].append(result)
            return result
        else:
            print("   âŒ æœªæ”¶é›†åˆ°èµ„æºæ•°æ®")
            return None
    
    def test_task_submission_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•ä»»åŠ¡æäº¤æ€§èƒ½"""
        print("ğŸš€ æµ‹è¯•ä»»åŠ¡æäº¤æ€§èƒ½...")
        
        task_types = [
            {
                'name': 'è½¬å½•ä»»åŠ¡',
                'endpoint': '/generate_text_from_video',
                'data': {'video_url': self.test_videos[0]}
            },
            {
                'name': 'ä¸‹è½½ä»»åŠ¡',
                'endpoint': '/download_video',
                'data': {
                    'video_url': self.test_videos[0],
                    'quality': '480p',
                    'format': 'mp4'
                }
            },
            {
                'name': 'å…³é”®å¸§ä»»åŠ¡',
                'endpoint': '/extract_keyframes',
                'data': {
                    'video_url': self.test_videos[0],
                    'method': 'count',
                    'count': 3
                }
            }
        ]
        
        submission_results = []
        
        for task_type in task_types:
            print(f"\n   ğŸ“¤ æµ‹è¯•{task_type['name']}æäº¤...")
            
            submission_times = []
            successful_submissions = 0
            
            for i in range(5):  # æ¯ç§ä»»åŠ¡ç±»å‹æäº¤5æ¬¡
                start_time = time.time()
                
                try:
                    response = self.session.post(
                        f"{self.api_base_url}{task_type['endpoint']}",
                        json=task_type['data']
                    )
                    
                    end_time = time.time()
                    submission_time = end_time - start_time
                    
                    if response.status_code in [200, 503]:
                        submission_times.append(submission_time)
                        if response.status_code == 200:
                            successful_submissions += 1
                    
                except Exception as e:
                    print(f"      âš ï¸ ç¬¬{i+1}æ¬¡æäº¤å¤±è´¥: {str(e)}")
                
                time.sleep(1)  # é—´éš”1ç§’
            
            if submission_times:
                avg_time = statistics.mean(submission_times)
                result = {
                    'task_type': task_type['name'],
                    'avg_submission_time': avg_time,
                    'successful_submissions': successful_submissions,
                    'total_attempts': 5,
                    'success_rate': successful_submissions / 5
                }
                
                print(f"      ğŸ“Š å¹³å‡æäº¤æ—¶é—´: {avg_time:.3f}s")
                print(f"      ğŸ“Š æˆåŠŸæäº¤: {successful_submissions}/5")
                
                submission_results.append(result)
        
        return {'task_submission_results': submission_results}
    
    def run_comprehensive_benchmark(self):
        """è¿è¡Œç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 80)
        
        # æ£€æŸ¥APIå¯ç”¨æ€§
        if not self.check_api_availability():
            print("âŒ APIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ")
            return False
        
        print("âœ… APIæœåŠ¡å¯ç”¨ï¼Œå¼€å§‹åŸºå‡†æµ‹è¯•...")
        
        # 1. å“åº”æ—¶é—´æµ‹è¯•
        print("\nğŸ“Š ç¬¬1é˜¶æ®µ: å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•")
        print("-" * 40)
        
        endpoints_to_test = [
            ('/health', 'GET', None),
            ('/system/resources', 'GET', None),
            ('/system/performance/stats', 'GET', None),
            ('/generate_text_from_video', 'POST', {'video_url': self.test_videos[0]}),
        ]
        
        for endpoint, method, data in endpoints_to_test:
            self.measure_response_time(endpoint, method, data, 5)
            time.sleep(1)
        
        # 2. å¹¶å‘æ€§èƒ½æµ‹è¯•
        print("\nğŸ”„ ç¬¬2é˜¶æ®µ: å¹¶å‘æ€§èƒ½æµ‹è¯•")
        print("-" * 40)
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹çš„å¹¶å‘æ€§èƒ½
        self.test_concurrent_requests('/health', 'GET', None, 5, 30)
        time.sleep(5)
        
        # æµ‹è¯•ä»»åŠ¡æäº¤çš„å¹¶å‘æ€§èƒ½
        self.test_concurrent_requests(
            '/generate_text_from_video', 
            'POST', 
            {'video_url': self.test_videos[0]}, 
            3, 
            20
        )
        time.sleep(5)
        
        # 3. èµ„æºä½¿ç”¨ç›‘æ§
        print("\nğŸ’» ç¬¬3é˜¶æ®µ: èµ„æºä½¿ç”¨ç›‘æ§")
        print("-" * 40)
        
        # åœ¨è´Ÿè½½ä¸‹ç›‘æ§èµ„æºä½¿ç”¨
        def create_load():
            """åˆ›å»ºç³»ç»Ÿè´Ÿè½½"""
            for _ in range(3):
                try:
                    self.session.post(
                        f"{self.api_base_url}/generate_text_from_video",
                        json={'video_url': self.test_videos[0]}
                    )
                except:
                    pass
                time.sleep(2)
        
        # å¯åŠ¨è´Ÿè½½ç”Ÿæˆçº¿ç¨‹
        load_thread = threading.Thread(target=create_load)
        load_thread.start()
        
        # ç›‘æ§èµ„æºä½¿ç”¨
        self.monitor_resource_usage(30)
        
        load_thread.join()
        
        # 4. ä»»åŠ¡æäº¤æ€§èƒ½æµ‹è¯•
        print("\nğŸš€ ç¬¬4é˜¶æ®µ: ä»»åŠ¡æäº¤æ€§èƒ½æµ‹è¯•")
        print("-" * 40)
        
        submission_results = self.test_task_submission_performance()
        self.results.update(submission_results)
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_benchmark_report()
        
        return True
    
    def generate_benchmark_report(self):
        """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)
        
        print(f"ğŸ• æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸŒ APIåœ°å€: {self.api_base_url}")
        
        # å“åº”æ—¶é—´æŠ¥å‘Š
        if self.results['response_times']:
            print("\nğŸ“Š å“åº”æ—¶é—´åŸºå‡†:")
            for result in self.results['response_times']:
                print(f"   {result['endpoint']} ({result['method']}):")
                print(f"      å¹³å‡: {result['avg_response_time']:.3f}s")
                print(f"      ä¸­ä½æ•°: {result['median_response_time']:.3f}s")
                print(f"      èŒƒå›´: {result['min_response_time']:.3f}s - {result['max_response_time']:.3f}s")
                print(f"      æˆåŠŸç‡: {result['success_rate']:.2%}")
        
        # å¹¶å‘æ€§èƒ½æŠ¥å‘Š
        if self.results['concurrent_tests']:
            print("\nğŸ”„ å¹¶å‘æ€§èƒ½åŸºå‡†:")
            for result in self.results['concurrent_tests']:
                print(f"   {result['endpoint']} ({result['concurrent_users']}å¹¶å‘ç”¨æˆ·):")
                print(f"      ååé‡: {result['throughput']:.2f} è¯·æ±‚/ç§’")
                print(f"      å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']:.3f}s")
                print(f"      æˆåŠŸç‡: {result['success_rate']:.2%}")
        
        # èµ„æºä½¿ç”¨æŠ¥å‘Š
        if self.results['resource_usage']:
            print("\nğŸ’» èµ„æºä½¿ç”¨åŸºå‡†:")
            for result in self.results['resource_usage']:
                print(f"   ç›‘æ§æ—¶é•¿: {result['duration']}ç§’ ({result['samples']}ä¸ªæ ·æœ¬)")
                print(f"   CPUä½¿ç”¨ç‡: å¹³å‡{result['cpu_stats']['avg']:.1f}%, å³°å€¼{result['cpu_stats']['max']:.1f}%")
                print(f"   å†…å­˜ä½¿ç”¨ç‡: å¹³å‡{result['memory_stats']['avg']:.1f}%, å³°å€¼{result['memory_stats']['max']:.1f}%")
                print(f"   æ´»è·ƒä»»åŠ¡æ•°: å¹³å‡{result['task_stats']['avg']:.1f}, å³°å€¼{result['task_stats']['max']}")
        
        # ä»»åŠ¡æäº¤æ€§èƒ½æŠ¥å‘Š
        if 'task_submission_results' in self.results:
            print("\nğŸš€ ä»»åŠ¡æäº¤æ€§èƒ½:")
            for result in self.results['task_submission_results']:
                print(f"   {result['task_type']}:")
                print(f"      å¹³å‡æäº¤æ—¶é—´: {result['avg_submission_time']:.3f}s")
                print(f"      æˆåŠŸç‡: {result['success_rate']:.2%}")
        
        # æ€§èƒ½è¯„ä¼°
        print("\nğŸ¯ æ€§èƒ½è¯„ä¼°:")
        
        # å“åº”æ—¶é—´è¯„ä¼°
        if self.results['response_times']:
            avg_response_times = [r['avg_response_time'] for r in self.results['response_times']]
            overall_avg = statistics.mean(avg_response_times)
            
            if overall_avg < 0.1:
                print("   âœ… å“åº”æ—¶é—´: ä¼˜ç§€ (< 100ms)")
            elif overall_avg < 0.5:
                print("   âœ… å“åº”æ—¶é—´: è‰¯å¥½ (< 500ms)")
            elif overall_avg < 1.0:
                print("   âš ï¸ å“åº”æ—¶é—´: ä¸€èˆ¬ (< 1s)")
            else:
                print("   âŒ å“åº”æ—¶é—´: éœ€è¦ä¼˜åŒ– (> 1s)")
        
        # å¹¶å‘æ€§èƒ½è¯„ä¼°
        if self.results['concurrent_tests']:
            throughputs = [r['throughput'] for r in self.results['concurrent_tests']]
            max_throughput = max(throughputs) if throughputs else 0
            
            if max_throughput > 10:
                print("   âœ… å¹¶å‘æ€§èƒ½: ä¼˜ç§€ (> 10 req/s)")
            elif max_throughput > 5:
                print("   âœ… å¹¶å‘æ€§èƒ½: è‰¯å¥½ (> 5 req/s)")
            elif max_throughput > 1:
                print("   âš ï¸ å¹¶å‘æ€§èƒ½: ä¸€èˆ¬ (> 1 req/s)")
            else:
                print("   âŒ å¹¶å‘æ€§èƒ½: éœ€è¦ä¼˜åŒ– (< 1 req/s)")
        
        # èµ„æºä½¿ç”¨è¯„ä¼°
        if self.results['resource_usage']:
            resource_result = self.results['resource_usage'][0]
            max_cpu = resource_result['cpu_stats']['max']
            max_memory = resource_result['memory_stats']['max']
            
            if max_cpu < 70 and max_memory < 80:
                print("   âœ… èµ„æºä½¿ç”¨: ä¼˜ç§€ (CPU < 70%, å†…å­˜ < 80%)")
            elif max_cpu < 85 and max_memory < 90:
                print("   âœ… èµ„æºä½¿ç”¨: è‰¯å¥½ (CPU < 85%, å†…å­˜ < 90%)")
            else:
                print("   âš ï¸ èµ„æºä½¿ç”¨: éœ€è¦å…³æ³¨ (CPUæˆ–å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜)")
        
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print("   - å®šæœŸè¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ç›‘æ§ç³»ç»Ÿæ€§èƒ½")
        print("   - æ ¹æ®è´Ÿè½½æƒ…å†µè°ƒæ•´å¹¶å‘é™åˆ¶å’Œèµ„æºé…ç½®")
        print("   - ç›‘æ§å…³é”®æ€§èƒ½æŒ‡æ ‡å¹¶è®¾ç½®å‘Šè­¦é˜ˆå€¼")
        print("   - è€ƒè™‘å¯ç”¨ç¼“å­˜å’Œç¡¬ä»¶åŠ é€Ÿä¼˜åŒ–")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è§†é¢‘å¤„ç†APIæ€§èƒ½åŸºå‡†æµ‹è¯•')
    parser.add_argument('--api-url', default='http://localhost:7878', help='APIæœåŠ¡åœ°å€')
    parser.add_argument('--test', choices=['response', 'concurrent', 'resource', 'submission', 'all'],
                       default='all', help='æŒ‡å®šè¦è¿è¡Œçš„æµ‹è¯•ç±»å‹')
    
    args = parser.parse_args()
    
    benchmark = PerformanceBenchmark(args.api_url)
    
    if args.test == 'all':
        success = benchmark.run_comprehensive_benchmark()
    elif args.test == 'response':
        # åªè¿è¡Œå“åº”æ—¶é—´æµ‹è¯•
        endpoints = [
            ('/health', 'GET', None),
            ('/system/resources', 'GET', None),
        ]
        for endpoint, method, data in endpoints:
            benchmark.measure_response_time(endpoint, method, data, 10)
        success = True
    elif args.test == 'concurrent':
        # åªè¿è¡Œå¹¶å‘æµ‹è¯•
        benchmark.test_concurrent_requests('/health', 'GET', None, 5, 30)
        success = True
    elif args.test == 'resource':
        # åªè¿è¡Œèµ„æºç›‘æ§
        benchmark.monitor_resource_usage(60)
        success = True
    elif args.test == 'submission':
        # åªè¿è¡Œä»»åŠ¡æäº¤æµ‹è¯•
        benchmark.test_task_submission_performance()
        success = True
    else:
        print(f"æœªçŸ¥çš„æµ‹è¯•ç±»å‹: {args.test}")
        success = False
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()