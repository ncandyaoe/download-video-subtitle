#!/usr/bin/env python3
"""
éŸ³é¢‘æ–‡æœ¬å¯¹é½å·¥å…·
åŸºäºç°æœ‰MP3éŸ³é¢‘å’ŒTXTæ–‡æœ¬ï¼Œç”Ÿæˆå®Œç¾å¯¹é½çš„å­—å¹•
"""

import os
import re
import json
from moviepy.editor import AudioFileClip
from faster_whisper import WhisperModel
from loguru import logger

class AudioTextAligner:
    """éŸ³é¢‘æ–‡æœ¬å¯¹é½å™¨"""
    
    def __init__(self, model_size="large-v3"):
        self.model_size = model_size
        self.model = None
        
    def load_whisper_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        if not self.model:
            logger.info(f"åŠ è½½Whisperæ¨¡å‹: {self.model_size}")
            self.model = WhisperModel(self.model_size, device="cpu", compute_type="int8")
        return self.model
    
    def split_text_by_punctuation(self, text):
        """æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²æ–‡æœ¬"""
        # åˆ†å‰²æ ‡ç‚¹ç¬¦å·ï¼Œä¿ç•™æ ‡ç‚¹
        segments = re.split(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›:,.!?;:])', text)
        
        result = []
        current = ""
        
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
                
            if segment in "ï¼Œã€‚ï¼ï¼Ÿï¼›:,.!?;:":
                # æ ‡ç‚¹ç¬¦å·ï¼Œæ·»åŠ åˆ°å½“å‰æ®µè½
                current += segment
                if current.strip():
                    result.append(current.strip())
                current = ""
            else:
                # æ–‡æœ¬å†…å®¹
                current += segment
        
        # å¤„ç†æœ€åä¸€æ®µ
        if current.strip():
            result.append(current.strip())
        
        return [s for s in result if s.strip()]
    
    def transcribe_with_word_timestamps(self, audio_file):
        """è½¬å½•éŸ³é¢‘å¹¶è·å–è¯çº§æ—¶é—´æˆ³"""
        model = self.load_whisper_model()
        
        logger.info(f"å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_file}")
        segments, info = model.transcribe(
            audio_file,
            beam_size=5,
            word_timestamps=True,
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=300),
        )
        
        logger.info(f"æ£€æµ‹è¯­è¨€: {info.language}, ç½®ä¿¡åº¦: {info.language_probability:.2f}")
        
        # æå–æ‰€æœ‰è¯å’Œæ—¶é—´æˆ³
        words_with_timestamps = []
        for segment in segments:
            if segment.words:
                for word in segment.words:
                    words_with_timestamps.append({
                        'word': word.word.strip(),
                        'start': word.start,
                        'end': word.end
                    })
        
        return words_with_timestamps, info.language
    
    def calculate_similarity(self, text1, text2):
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„å­—ç¬¦çº§ç›¸ä¼¼åº¦è®¡ç®—
        text1 = re.sub(r'[^\w\s]', '', text1.lower())
        text2 = re.sub(r'[^\w\s]', '', text2.lower())
        
        if not text1 or not text2:
            return 0.0
        
        # ä½¿ç”¨æœ€é•¿å…¬å…±å­åºåˆ—
        def lcs_length(s1, s2):
            m, n = len(s1), len(s2)
            dp = [[0] * (n + 1) for _ in range(m + 1)]
            
            for i in range(1, m + 1):
                for j in range(1, n + 1):
                    if s1[i-1] == s2[j-1]:
                        dp[i][j] = dp[i-1][j-1] + 1
                    else:
                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            
            return dp[m][n]
        
        lcs_len = lcs_length(text1, text2)
        max_len = max(len(text1), len(text2))
        
        return lcs_len / max_len if max_len > 0 else 0.0
    
    def align_text_segments(self, txt_segments, transcribed_words):
        """å°†æ–‡æœ¬æ®µè½ä¸è½¬å½•è¯å¯¹é½"""
        logger.info(f"å¼€å§‹å¯¹é½ {len(txt_segments)} ä¸ªæ–‡æœ¬æ®µè½å’Œ {len(transcribed_words)} ä¸ªè½¬å½•è¯")
        
        aligned_segments = []
        word_index = 0
        
        for i, txt_segment in enumerate(txt_segments):
            logger.debug(f"å¤„ç†æ–‡æœ¬æ®µè½ {i+1}: {txt_segment[:50]}...")
            
            # æ¸…ç†æ–‡æœ¬ç”¨äºåŒ¹é…
            clean_txt = re.sub(r'[^\w\s]', '', txt_segment.lower())
            txt_words = clean_txt.split()
            
            if not txt_words:
                continue
            
            # å¯»æ‰¾æœ€ä½³åŒ¹é…çš„èµ·å§‹ä½ç½®
            best_start_index = word_index
            best_similarity = 0.0
            
            # åœ¨å½“å‰ä½ç½®é™„è¿‘æœç´¢æœ€ä½³åŒ¹é…
            search_range = min(50, len(transcribed_words) - word_index)
            
            for offset in range(search_range):
                test_index = word_index + offset
                if test_index >= len(transcribed_words):
                    break
                
                # æ„å»ºæµ‹è¯•æ–‡æœ¬
                test_words = []
                for j in range(test_index, min(test_index + len(txt_words) * 2, len(transcribed_words))):
                    test_words.append(re.sub(r'[^\w\s]', '', transcribed_words[j]['word'].lower()))
                
                test_text = ' '.join(test_words)
                similarity = self.calculate_similarity(clean_txt, test_text)
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_start_index = test_index
            
            # ç¡®å®šæ®µè½çš„æ—¶é—´èŒƒå›´
            if best_start_index < len(transcribed_words):
                start_time = transcribed_words[best_start_index]['start']
                
                # ä¼°ç®—ç»“æŸæ—¶é—´
                estimated_word_count = len(txt_words)
                end_index = min(best_start_index + estimated_word_count, len(transcribed_words) - 1)
                
                # å¾®è°ƒç»“æŸä½ç½®
                for j in range(best_start_index + 1, min(best_start_index + estimated_word_count * 2, len(transcribed_words))):
                    current_text = ' '.join([re.sub(r'[^\w\s]', '', transcribed_words[k]['word'].lower()) 
                                           for k in range(best_start_index, j + 1)])
                    
                    if self.calculate_similarity(clean_txt, current_text) > 0.7:
                        end_index = j
                    else:
                        break
                
                end_time = transcribed_words[end_index]['end']
                
                # ç¡®ä¿æœ€å°æ—¶é•¿
                if end_time - start_time < 1.0:
                    end_time = start_time + max(1.0, len(txt_segment) * 0.1)
                
                aligned_segments.append({
                    'text': txt_segment,
                    'start_time': start_time,
                    'end_time': end_time,
                    'confidence': best_similarity
                })
                
                word_index = end_index + 1
                logger.debug(f"å¯¹é½æˆåŠŸ: {start_time:.2f}s - {end_time:.2f}s, ç½®ä¿¡åº¦: {best_similarity:.2f}")
            else:
                # å¦‚æœæ— æ³•æ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨ä¼°ç®—æ—¶é—´
                if aligned_segments:
                    last_end = aligned_segments[-1]['end_time']
                    estimated_duration = len(txt_segment) * 0.15
                    aligned_segments.append({
                        'text': txt_segment,
                        'start_time': last_end,
                        'end_time': last_end + estimated_duration,
                        'confidence': 0.0
                    })
                else:
                    estimated_duration = len(txt_segment) * 0.15
                    aligned_segments.append({
                        'text': txt_segment,
                        'start_time': 0.0,
                        'end_time': estimated_duration,
                        'confidence': 0.0
                    })
                
                logger.warning(f"æ— æ³•å¯¹é½æ®µè½ï¼Œä½¿ç”¨ä¼°ç®—æ—¶é—´: {txt_segment[:30]}...")
        
        return aligned_segments
    
    def generate_srt(self, aligned_segments, output_file):
        """ç”ŸæˆSRTå­—å¹•æ–‡ä»¶"""
        def format_time(seconds):
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            milliseconds = int((seconds % 1) * 1000)
            return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(aligned_segments, 1):
                start_time = format_time(segment['start_time'])
                end_time = format_time(segment['end_time'])
                
                f.write(f"{i}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{segment['text']}\n\n")
        
        logger.info(f"SRTå­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
        return output_file
    
    def align_audio_text(self, audio_file, txt_file, output_srt_file):
        """ä¸»è¦å¯¹é½å‡½æ•°"""
        logger.info("å¼€å§‹éŸ³é¢‘æ–‡æœ¬å¯¹é½æµç¨‹")
        
        # 1. è¯»å–æ–‡æœ¬æ–‡ä»¶
        with open(txt_file, 'r', encoding='utf-8') as f:
            txt_content = f.read().strip()
        
        if not txt_content:
            raise ValueError("æ–‡æœ¬æ–‡ä»¶ä¸ºç©º")
        
        logger.info(f"æ–‡æœ¬å†…å®¹é•¿åº¦: {len(txt_content)} å­—ç¬¦")
        
        # 2. åˆ†å‰²æ–‡æœ¬
        txt_segments = self.split_text_by_punctuation(txt_content)
        logger.info(f"æ–‡æœ¬åˆ†å‰²ä¸º {len(txt_segments)} ä¸ªæ®µè½")
        
        # 3. è½¬å½•éŸ³é¢‘è·å–æ—¶é—´æˆ³
        transcribed_words, language = self.transcribe_with_word_timestamps(audio_file)
        logger.info(f"è½¬å½•è·å¾— {len(transcribed_words)} ä¸ªè¯çš„æ—¶é—´æˆ³")
        
        # 4. å¯¹é½æ–‡æœ¬å’ŒéŸ³é¢‘
        aligned_segments = self.align_text_segments(txt_segments, transcribed_words)
        
        # 5. ç”ŸæˆSRTæ–‡ä»¶
        srt_file = self.generate_srt(aligned_segments, output_srt_file)
        
        # 6. ç”Ÿæˆå¯¹é½æŠ¥å‘Š
        total_confidence = sum(seg['confidence'] for seg in aligned_segments)
        avg_confidence = total_confidence / len(aligned_segments) if aligned_segments else 0
        
        report = {
            'audio_file': audio_file,
            'txt_file': txt_file,
            'srt_file': srt_file,
            'language': language,
            'total_segments': len(aligned_segments),
            'average_confidence': avg_confidence,
            'segments': aligned_segments
        }
        
        logger.info(f"å¯¹é½å®Œæˆ! å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.2f}")
        return report

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # ä½¿ç”¨ç¤ºä¾‹
    aligner = AudioTextAligner()
    
    # è¾“å…¥æ–‡ä»¶
    audio_file = "your_audio.mp3"  # ä½ çš„éŸ³é¢‘æ–‡ä»¶
    txt_file = "your_script.txt"   # ä½ çš„æ–‡æœ¬æ–‡ä»¶
    output_srt = "aligned_subtitle.srt"  # è¾“å‡ºå­—å¹•æ–‡ä»¶
    
    try:
        # æ‰§è¡Œå¯¹é½
        report = aligner.align_audio_text(audio_file, txt_file, output_srt)
        
        print("ğŸ‰ å¯¹é½å®Œæˆ!")
        print(f"ğŸ“ å­—å¹•æ–‡ä»¶: {report['srt_file']}")
        print(f"ğŸŒ æ£€æµ‹è¯­è¨€: {report['language']}")
        print(f"ğŸ“Š æ®µè½æ•°é‡: {report['total_segments']}")
        print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {report['average_confidence']:.2f}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ®µè½çš„å¯¹é½ç»“æœ
        print("\nğŸ“‹ å¯¹é½ç»“æœé¢„è§ˆ:")
        for i, segment in enumerate(report['segments'][:3]):
            print(f"  {i+1}. [{segment['start_time']:.2f}s - {segment['end_time']:.2f}s] "
                  f"ç½®ä¿¡åº¦: {segment['confidence']:.2f}")
            print(f"     {segment['text'][:50]}...")
        
    except Exception as e:
        print(f"âŒ å¯¹é½å¤±è´¥: {e}")

if __name__ == "__main__":
    main()